{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "\n",
    "\n",
    "class KaggleWord2VecUtility(object):\n",
    "\n",
    "\n",
    "        @staticmethod\n",
    "        def review_to_wordlist(review,stem=False):\n",
    "            # Function to convert a document to a sequence of words,\n",
    "            # optionally removing stop words.  Returns a list of words.\n",
    "            #\n",
    "            tknzr = TweetTokenizer()\n",
    "            new_temp=[]\n",
    "            review=str(review)\n",
    "            new_temp=re.sub('\\\\<.*?\\\\>', \"\", review)\n",
    "            new_temp=re.sub('\\\\http.*[\\s]',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\http.*$',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\@(.*?)[\\s]',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\@(.*?)$',\"\",new_temp)\n",
    "            #new_temp=re.sub('\\\\#(.*?)[\\s]',\"\",new_temp)# if accuracy is less, try removing this\n",
    "            #new_temp=re.sub('\\\\#(.*?)$',\"\",new_temp)# if accuracy is less, try removing this\n",
    "            new_temp=re.sub(r'[^\\w\\s]',\"\",new_temp)\n",
    "\n",
    "            review_text=re.sub('\\d+', \"\",new_temp)#does this hamper performance\n",
    "\n",
    "            words = review_text.lower().split()\n",
    "            if  stem:\n",
    "                ar1=[]\n",
    "                ps=PorterStemmer()\n",
    "                lanc=LancasterStemmer()\n",
    "                lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "                sno=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "                words = [sno.stem(w) for w in words]\n",
    "                words = [ps.stem(w) for w in words]\n",
    "\n",
    "\n",
    "            return(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import bigrams\n",
    "from nltk.stem.porter import *\n",
    "import xlrd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sklearn\n",
    "#from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN,BRkNNaClassifier,BRkNNbClassifier\n",
    "\n",
    "\n",
    "#path = \"D:\\H\\Dataset\\Book_Dataset_clean.csv\"\n",
    "#df = pd.read_csv(path)\n",
    "df = pd.read_csv('/home/pramod/Transfer/Book_Dataset_clean.csv')\n",
    "\n",
    "genre = df['Genre'][0:1000]\n",
    "summ = df[\"Summary\"][0:1000]\n",
    "result = []\n",
    "\n",
    "\n",
    "for xi in genre:\n",
    "    abc = re.sub(r'\"/[a-zA-Z/0-9 ]+\": ',\"\",xi)\n",
    "    abc = re.sub(r'[{}\\\"\\\"]+',\"\",abc)\n",
    "    abc = re.sub(r'\\\\u00e0',\"a\",abc)\n",
    "    abc = re.sub(r'/[a-zA-Z/0-9\\_]+: ',\"\",abc)\n",
    "    abc = re.sub(r', ',\",\",abc)\n",
    "    result.append(abc)\n",
    "    \n",
    "genre_arr = np.array([np.array(xi.split(\",\")) for xi in result])\n",
    "\n",
    "\n",
    "clean_summaries=[]\n",
    "for i in range(0,len(summ)):\n",
    "    clean_summaries.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(summ[i],True)))\n",
    "clean_summaries = np.array(clean_summaries)\n",
    "\n",
    "#print(clean_summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2=[]\n",
    "for i in genre_arr:\n",
    "    arr3=[]\n",
    "    for a in i:\n",
    "        if a == 'Hard science fiction':\n",
    "            b=a.replace('Hard science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Young adult literature':\n",
    "            b=a.replace('Young adult literature',\"Children's literature\")\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical novel':\n",
    "            b=a.replace('Historical novel','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical fiction':\n",
    "            b=a.replace('Historical fiction','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Alternate history':\n",
    "            b=a.replace('Alternate history','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'War novel':\n",
    "            b=a.replace('War novel','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Novella':\n",
    "            b=a.replace('Novella','Novel')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic novel':\n",
    "            b=a.replace('Comic novel','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Autobiographical novel':\n",
    "            b=a.replace('Autobiographical novel','Autobiography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'High fantasy':\n",
    "            b=a.replace('High fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'History':\n",
    "            b=a.replace('History','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Memoir':\n",
    "            b=a.replace('Memoir','Biography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Techno-thriller':\n",
    "            b=a.replace('Techno-thriller','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Steampunk':\n",
    "            b=a.replace('Steampunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Paranormal romance':\n",
    "            b=a.replace('Paranormal romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Romance novel':\n",
    "            b=a.replace('Romance novel','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Picture book':\n",
    "            b=a.replace('Picture book',\"Children's literature\")\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bildungsroman':\n",
    "            b=a.replace('Bildungsroman','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Reference':\n",
    "            b=a.replace('Reference','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Black comedy':\n",
    "            b=a.replace('Black comedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Urban fantasy':\n",
    "            b=a.replace('Urban fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Military science fiction':\n",
    "            b=a.replace('Military science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sword and sorcery':\n",
    "            b=a.replace('Sword and sorcery','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Whodunit':\n",
    "            b=a.replace('Whodunit','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Absurdist fiction':\n",
    "            b=a.replace('Absurdist fiction','Literary fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Hardboiled':\n",
    "            b=a.replace('Hardboiled','Detective fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Science':\n",
    "            b=a.replace('Science','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dark fantasy':\n",
    "            b=a.replace('Dark fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Time travel':\n",
    "            b=a.replace('Time travel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Psychological novel':\n",
    "            b=a.replace('Psychological novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Adventure novel':\n",
    "            b=a.replace('Adventure novel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Wuxia':\n",
    "            b=a.replace('Wuxia','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Picaresque novel':\n",
    "            b=a.replace('Picaresque novel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'True crime':\n",
    "            b=a.replace('True crime','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cyberpunk':\n",
    "            b=a.replace('Cyberpunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical fantasy':\n",
    "            b=a.replace('Historical fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Vampire fiction':\n",
    "            b=a.replace('Vampire fiction','Gothic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Religion':\n",
    "            b=a.replace('Religion','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Scientific romance':\n",
    "            b=a.replace('Scientific romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Lost World':\n",
    "            b=a.replace('Lost World','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Space opera':\n",
    "            b=a.replace('Space opera','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Chivalric romance':\n",
    "            b=a.replace('Chivalric romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'K\\\\u00fcnstlerroman':\n",
    "            b=a.replace('K\\\\u00fcnstlerroman','Kunstlerroman')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Biographical novel':\n",
    "            b=a.replace('Biographical novel','Biography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Travel literature':\n",
    "            b=a.replace('Travel literature','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Science fantasy':\n",
    "            b=a.replace('Science fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic book':\n",
    "            b=a.replace('Comic book','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Kunstlerroman':\n",
    "            b=a.replace('Kunstlerroman','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Drama':\n",
    "            b=a.replace('Drama','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Parody':\n",
    "            b=a.replace('Parody','Satire')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Travel':\n",
    "            b=a.replace('Travel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Magic realism':\n",
    "            b=a.replace('Magic realism','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Epistolary novel':\n",
    "            b=a.replace('Epistolary novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #After this\n",
    "        elif a == 'Politics':\n",
    "            b=a.replace('Politics','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Mathematics':\n",
    "            b=a.replace('Mathematics','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Marketing':\n",
    "            b=a.replace('Marketing','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'American Gothic Fiction':\n",
    "            b=a.replace('American Gothic Fiction','Gothic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Police procedural':\n",
    "            b=a.replace('Police procedural','Detective fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Human extinction':\n",
    "            b=a.replace('Human extinction','Apocalyptic and post-apocalyptic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Utopian fiction':\n",
    "            b=a.replace('Utopian fiction','Utopian and dystopian fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Photography':\n",
    "            b=a.replace('Photography','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Future history':\n",
    "            b=a.replace('Future history','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fantastique':\n",
    "            b=a.replace('Fantastique','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Popular culture':\n",
    "            b=a.replace('Popular culture','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Robinsonade':\n",
    "            b=a.replace('Robinsonade','Travel')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Conspiracy':\n",
    "            b=a.replace('Conspiracy','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Colonial United States romance':\n",
    "            b=a.replace('Colonial United States romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Experimental literature':\n",
    "            b=a.replace('Experimental literature','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Religious text':\n",
    "            b=a.replace('Religious text','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'English public-school stories':\n",
    "            b=a.replace('English public-school stories','Fiction')\n",
    "            arr3.append(b)       \n",
    "        elif a == 'School story':\n",
    "            b=a.replace('School story','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == \"Boys' school stories\":\n",
    "            b=a.replace(\"Boys' school stories\",'Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social criticism':\n",
    "            b=a.replace('Social criticism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Computer Science':\n",
    "            b=a.replace('Computer Science','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Pornography':\n",
    "            b=a.replace('Pornography','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bit Lit':\n",
    "            b=a.replace('Bit Lit','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Georgian romance':\n",
    "            b=a.replace('Georgian romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Superhero fiction':\n",
    "            b=a.replace('Superhero fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'New Weird':\n",
    "            b=a.replace('New Weird','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Alien invasion':\n",
    "            b=a.replace('Alien invasion','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Low fantasy':\n",
    "            b=a.replace('Low fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'New York Times Best Seller list':\n",
    "            b=a.replace('New York Times Best Seller list','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Western fiction':\n",
    "            b=a.replace('Western fiction','Western')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Neuroscience':\n",
    "            b=a.replace('Neuroscience','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Juvenile fantasy':\n",
    "            b=a.replace('Juvenile fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Medieval romance':\n",
    "            b=a.replace('Medieval romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Romantic comedy':\n",
    "            b=a.replace('Romantic comedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Foreign legion':\n",
    "            b=a.replace('Foreign legion','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fable':\n",
    "            b=a.replace('Fable','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Elizabethan romance':\n",
    "            b=a.replace('Elizabethan romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Metaphysics':\n",
    "            b=a.replace('Metaphysics','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bangsian fantasy':\n",
    "            b=a.replace('Bangsian fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Indian chick lit':\n",
    "            b=a.replace('Indian chick lit','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Epic Science Fiction and Fantasy':\n",
    "            b=a.replace('Epic Science Fiction and Fantasy','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Naval adventure':\n",
    "            b=a.replace('Naval adventure','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cookbook':\n",
    "            b=a.replace('Cookbook','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Albino bias':\n",
    "            b=a.replace('Albino bias','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Morality play':\n",
    "            b=a.replace('Morality play','Drama')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Polemic':\n",
    "            b=a.replace('Polemic','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Literary criticism':\n",
    "            b=a.replace('Literary criticism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Creative nonfiction':\n",
    "            b=a.replace('Creative nonfiction','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Postcyberpunk':\n",
    "            b=a.replace('Postcyberpunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fairytale fantasy':\n",
    "            b=a.replace('Fairytale fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Modernism':\n",
    "            b=a.replace('Modernism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Political philosophy':\n",
    "            b=a.replace('Political philosophy','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anti-war':\n",
    "            b=a.replace('Anti-war','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Gay Themed':\n",
    "            b=a.replace('Gay Themed','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Military history':\n",
    "            b=a.replace('Military history','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'First-person narrative':\n",
    "            b=a.replace('First-person narrative','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fictional crossover':\n",
    "            b=a.replace('Fictional crossover','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Space western':\n",
    "            b=a.replace('Space western','Western')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social novel':\n",
    "            b=a.replace('Social novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Heroic fantasy':\n",
    "            b=a.replace('Heroic fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sea story':\n",
    "            b=a.replace('Sea story','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Coming of age':\n",
    "            b=a.replace('Coming of age','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Self-help':\n",
    "            b=a.replace('Self-help','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Catastrophic literature':\n",
    "            b=a.replace('Catastrophic literature','Apocalyptic and post-apocalyptic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dying Earth subgenre':\n",
    "            b=a.replace('Dying Earth subgenre','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Zombies in popular culture':\n",
    "            b=a.replace('Zombies in popular culture','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social sciences':\n",
    "            b=a.replace('Social sciences','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Treatise':\n",
    "            b=a.replace('Treatise','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Essay':\n",
    "            b=a.replace('Essay','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Prose poetry':\n",
    "            b=a.replace('Prose poetry','Prose')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Ergodic literature':\n",
    "            b=a.replace('Ergodic literature','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Non-fiction novel':\n",
    "            b=a.replace('Non-fiction novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'LGBT literature':\n",
    "            b=a.replace('LGBT literature','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Transgender and transsexual fiction':\n",
    "            b=a.replace('Transgender and transsexual fiction','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social commentary':\n",
    "            b=a.replace('Social commentary','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sword and planet':\n",
    "            b=a.replace('Sword and planet','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Biopunk':\n",
    "            b=a.replace('Biopunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comedy of manners':\n",
    "            b=a.replace('Comedy of manners','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Locked room mystery':\n",
    "            b=a.replace('Locked room mystery','Mystery')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Industrial novel':\n",
    "            b=a.replace('Industrial novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Industrial novel':\n",
    "            b=a.replace('Industrial novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Mashup':\n",
    "            b=a.replace('Mashup','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Edisonade':\n",
    "            b=a.replace('Edisonade','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Farce':\n",
    "            b=a.replace('Farce','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical romance':\n",
    "            b=a.replace('Historical romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Conspiracy fiction':\n",
    "            b=a.replace('Conspiracy fiction','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Spirituality':\n",
    "            b=a.replace('Spirituality','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Zombie':\n",
    "            b=a.replace('Zombie','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Subterranean fiction':\n",
    "            b=a.replace('Subterranean fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Ghost story':\n",
    "            b=a.replace('Ghost story','Horror')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Supernatural':\n",
    "            b=a.replace('Supernatural','Horror')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anthropology':\n",
    "            b=a.replace('Anthropology','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sports':\n",
    "            b=a.replace('Sports','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Post-holocaust':\n",
    "            b=a.replace('Post-holocaust','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic fantasy':\n",
    "            b=a.replace('Comic fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Planetary romance':\n",
    "            b=a.replace('Planetary romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comics':\n",
    "            b=a.replace('Comics','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Chick lit':\n",
    "            b=a.replace('Chick lit','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cozy':\n",
    "            b=a.replace('Cozy','Crime Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Inspirational':\n",
    "            b=a.replace('Inspirational','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fantasy of manners':\n",
    "            b=a.replace('Fantasy of manners','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anthology':\n",
    "            b=a.replace('Anthology','Short story')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Contemporary fantasy':\n",
    "            b=a.replace('Contemporary fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Transhumanism':\n",
    "            b=a.replace('Transhumanism','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Campus novel':\n",
    "            b=a.replace('Campus novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Soft science fiction':\n",
    "            b=a.replace('Soft science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic fantasy':\n",
    "            b=a.replace('Comic fantasy','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Urban fiction':\n",
    "            b=a.replace('Urban fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social science fiction':\n",
    "            b=a.replace('Social science fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Economics':\n",
    "            b=a.replace('Economics','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Erotica':\n",
    "            b=a.replace('Erotica','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Graphic novel':\n",
    "            b=a.replace('Graphic novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Regency romance':\n",
    "            b=a.replace('Regency romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Tragicomedy':\n",
    "            b=a.replace('Tragicomedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fairy tale':\n",
    "            b=a.replace('Fairy tale','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Literary realism':\n",
    "            b=a.replace('Literary realism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Existentialism':\n",
    "            b=a.replace('Existentialism','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Popular science':\n",
    "            b=a.replace('Popular science','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Feminist science fiction':\n",
    "            b=a.replace('Feminist science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Postmodernism':\n",
    "            b=a.replace('Postmodernism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Personal journal':\n",
    "            b=a.replace('Personal journal','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Gay novel':\n",
    "            b=a.replace('Gay novel','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic science fiction':\n",
    "            b=a.replace('Comic science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical whodunnit':\n",
    "            b=a.replace('Historical whodunnit','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Psychology':\n",
    "            b=a.replace('Psychology','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dystopia':\n",
    "            b=a.replace('Dystopia','Utopian and dystopian fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sociology':\n",
    "            b=a.replace('Sociology','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        else:\n",
    "            arr3.append(a)\n",
    "    arr2.append(arr3)\n",
    "#print (arr2)\n",
    "#print(len(arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Fiction': 622, 'Speculative fiction': 490, 'Science Fiction': 359, 'Novel': 290, 'Fantasy': 197, \"Children's literature\": 192, 'Historical': 100, 'Mystery': 84, 'Non-fiction': 71, 'Suspense': 67, 'Romance': 58, 'Horror': 58, 'Utopian and dystopian fiction': 51, 'Adventure': 43, 'Crime Fiction': 36, 'Thriller': 36, 'Satire': 30, 'Autobiography': 29, 'Comedy': 29, 'Gothic fiction': 20, 'Detective fiction': 20, 'Philosophy': 19, 'Spy fiction': 17, 'Biography': 17, 'Humour': 15, 'Comic': 14, 'Roman a clef': 13, 'Poetry': 11, 'Apocalyptic and post-apocalyptic fiction': 11, 'Literary fiction': 9, 'Short story': 7, 'Western': 5, 'Kunstlerroman': 4, 'Business': 3, 'Music': 2, 'Role-playing game': 2, 'Nature': 2, 'Parallel novel': 2, 'Invasion literature': 1, 'Play': 1, 'Drama': 1, 'Prose': 1})\n",
      "42\n",
      "Counter({'Fiction': 622, 'Speculative fiction': 490, 'Science Fiction': 359, 'Novel': 290, 'Fantasy': 197, \"Children's literature\": 192, 'Historical': 100, 'Mystery': 84, 'Non-fiction': 71, 'Suspense': 67, 'Horror': 58, 'Romance': 58, 'Utopian and dystopian fiction': 51, 'Adventure': 43, 'Crime Fiction': 36, 'Thriller': 36, 'Satire': 30, 'Autobiography': 29, 'Comedy': 29})\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "array1=[]\n",
    "totals = Counter(i for i in list(itertools.chain.from_iterable(arr2)))\n",
    "\n",
    "print(totals)\n",
    "print(len(totals))\n",
    "\n",
    "for genre in totals:\n",
    "    if totals.get(genre)<=25:\n",
    "        array1.append(genre)\n",
    "array3=[a for a in totals]\n",
    "#print(array3)\n",
    "#print(len(array3))\n",
    "\n",
    "\n",
    "\n",
    "array2=([[genre for genre in i if genre not in array1]for i in arr2])\n",
    "\n",
    "\n",
    "res = Counter(i for i in list(itertools.chain.from_iterable(array2)))\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 64)           960000    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 496, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 248, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 246, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 123, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7872)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 19)                149587    \n",
      "=================================================================\n",
      "Total params: 1,142,483\n",
      "Trainable params: 1,142,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.3620 - acc: 0.8566 - fmeasure: 0.3643 - val_loss: 0.3438 - val_acc: 0.8618 - val_fmeasure: 0.3160\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 4s 7ms/step - loss: 0.3050 - acc: 0.8727 - fmeasure: 0.3809 - val_loss: 0.3420 - val_acc: 0.8566 - val_fmeasure: 0.3838\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2992 - acc: 0.8735 - fmeasure: 0.4074 - val_loss: 0.3465 - val_acc: 0.8530 - val_fmeasure: 0.3383\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2885 - acc: 0.8799 - fmeasure: 0.4168 - val_loss: 0.3415 - val_acc: 0.8595 - val_fmeasure: 0.2342\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2663 - acc: 0.8917 - fmeasure: 0.4824 - val_loss: 0.3303 - val_acc: 0.8658 - val_fmeasure: 0.4279\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.2174 - acc: 0.9148 - fmeasure: 0.6232 - val_loss: 0.3292 - val_acc: 0.8740 - val_fmeasure: 0.4182\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 4s 7ms/step - loss: 0.1597 - acc: 0.9373 - fmeasure: 0.7421 - val_loss: 0.3415 - val_acc: 0.8737 - val_fmeasure: 0.4409\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 5s 7ms/step - loss: 0.0950 - acc: 0.9674 - fmeasure: 0.8710 - val_loss: 0.3847 - val_acc: 0.8704 - val_fmeasure: 0.4643\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 4s 7ms/step - loss: 0.0450 - acc: 0.9870 - fmeasure: 0.9514 - val_loss: 0.4815 - val_acc: 0.8668 - val_fmeasure: 0.4824\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 4s 6ms/step - loss: 0.0247 - acc: 0.9933 - fmeasure: 0.9753 - val_loss: 0.6223 - val_acc: 0.8704 - val_fmeasure: 0.4609\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 4s 7ms/step - loss: 0.0142 - acc: 0.9971 - fmeasure: 0.9896 - val_loss: 0.6776 - val_acc: 0.8618 - val_fmeasure: 0.4562\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0084 - acc: 0.9984 - fmeasure: 0.9941 - val_loss: 0.7729 - val_acc: 0.8582 - val_fmeasure: 0.4578\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 0.0061 - acc: 0.9992 - fmeasure: 0.9970 - val_loss: 0.7783 - val_acc: 0.8687 - val_fmeasure: 0.4623\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0031 - acc: 0.9998 - fmeasure: 0.9991 - val_loss: 0.8428 - val_acc: 0.8645 - val_fmeasure: 0.4775\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0021 - acc: 0.9998 - fmeasure: 0.9990 - val_loss: 0.8431 - val_acc: 0.8694 - val_fmeasure: 0.4901\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0014 - acc: 0.9999 - fmeasure: 0.9996 - val_loss: 0.8654 - val_acc: 0.8661 - val_fmeasure: 0.4609\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 6s 9ms/step - loss: 9.6269e-04 - acc: 1.0000 - fmeasure: 1.0000 - val_loss: 0.9048 - val_acc: 0.8704 - val_fmeasure: 0.4667\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 7.3322e-04 - acc: 1.0000 - fmeasure: 1.0000 - val_loss: 0.9188 - val_acc: 0.8711 - val_fmeasure: 0.4796\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 5s 7ms/step - loss: 5.6792e-04 - acc: 1.0000 - fmeasure: 1.0000 - val_loss: 0.9392 - val_acc: 0.8714 - val_fmeasure: 0.4669\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 5s 7ms/step - loss: 4.5273e-04 - acc: 1.0000 - fmeasure: 1.0000 - val_loss: 0.9466 - val_acc: 0.8697 - val_fmeasure: 0.4694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1a2af1690>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "'''clean_train_reviews=np.array(entity)\n",
    "a=np.array(data1[\"Class\"][0:len(data)])\n",
    "\n",
    "cr=[x.encode('UTF8') for x in clean_train_reviews]\n",
    "'''\n",
    "b= np_utils.to_categorical(Y,3)\n",
    "\n",
    "tokenizer = Tokenizer(15000)\n",
    "tokenizer.fit_on_texts(clean_summaries)\n",
    "sequences = tokenizer.texts_to_sequences(clean_summaries)\n",
    "data = pad_sequences(sequences, maxlen=500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "'''X_train = X_train.reshape(X_train.shape[0], 1,100,100).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,100,100).astype('float32')\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)'''\n",
    "print (X_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(15000, 64, input_length=500))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(64,5, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64,3,activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(19,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',fmeasure])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=20,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 500, 64)           960000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 19)                1919      \n",
      "=================================================================\n",
      "Total params: 1,027,919\n",
      "Trainable params: 1,027,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "640/640 [==============================] - 36s 56ms/step - loss: 0.4307 - acc: 0.8391 - fmeasure: 0.3310 - val_loss: 0.3405 - val_acc: 0.8618 - val_fmeasure: 0.3147\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 33s 51ms/step - loss: 0.3301 - acc: 0.8632 - fmeasure: 0.3435 - val_loss: 0.3393 - val_acc: 0.8618 - val_fmeasure: 0.3147\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 34s 53ms/step - loss: 0.3266 - acc: 0.8644 - fmeasure: 0.3457 - val_loss: 0.3397 - val_acc: 0.8618 - val_fmeasure: 0.3147\n",
      "Epoch 4/10\n",
      "240/640 [==========>...................] - ETA: 20s - loss: 0.3222 - acc: 0.8671 - fmeasure: 0.3777"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "'''clean_train_reviews=np.array(entity)\n",
    "a=np.array(data1[\"Class\"][0:len(data)])\n",
    "\n",
    "cr=[x.encode('UTF8') for x in clean_train_reviews]\n",
    "'''\n",
    "b= np_utils.to_categorical(Y,3)\n",
    "\n",
    "tokenizer = Tokenizer(15000)\n",
    "tokenizer.fit_on_texts(clean_summaries)\n",
    "sequences = tokenizer.texts_to_sequences(clean_summaries)\n",
    "data = pad_sequences(sequences, maxlen=500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "'''X_train = X_train.reshape(X_train.shape[0], 1,100,100).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,100,100).astype('float32')\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)'''\n",
    "print (X_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(15000, 64, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(19,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',fmeasure])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=10,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "pred[pred>=0.5] = 1\n",
    "\n",
    "pred[pred<0.5] = 0\n",
    "\n",
    "print pred[1]\n",
    "\n",
    "x=mlb.inverse_transform(pred)\n",
    "\n",
    "actual=mlb.inverse_transform(y_test)\n",
    "\n",
    "print actual[1]\n",
    "\n",
    "print x[1]\n",
    "\n",
    "print f1_score(y_test, pred, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.425\n",
      "[ 0.03153045  0.02197548  0.18320118  0.02625101  0.02899649  0.20028158\n",
      "  0.5576902   0.06738926  0.04891956  0.05601579  0.06175901  0.14321209\n",
      "  0.03125753  0.03086173  0.2824029   0.62573618  0.0429874   0.02156149\n",
      "  0.02868323]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "('Adventure', 'Fantasy', 'Fiction', 'Romance', 'Speculative fiction')\n",
      "('Speculative fiction',)\n"
     ]
    }
   ],
   "source": [
    " from sklearn.metrics import coverage_error\n",
    "from scipy.sparse import lil_matrix\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in pred:\n",
    "    #print (i)\n",
    "    tempx=[]\n",
    "    for a in i:\n",
    "        if a<0.6:\n",
    "            a=0;\n",
    "            tempx.append(a);\n",
    "        else:\n",
    "            a=1;\n",
    "            tempx.append(a);\n",
    "    result.append(tempx)\n",
    "#result=np.array(result)\n",
    "\n",
    "result = lil_matrix(result)\n",
    "#print (result)\n",
    "print (coverage_error(y_test,pred))\n",
    "result=mlb.inverse_transform(result)\n",
    "actual=mlb.inverse_transform(y_test)\n",
    "print (pred[1])\n",
    "print(y_test[1])\n",
    "print (actual[1])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 14.24%\n",
      "test score is  0.361108772755\n",
      "test accuracy is  0.857631587982\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print (\"test score is \",scores[0])\n",
    "print ('test accuracy is ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
