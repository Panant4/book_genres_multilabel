{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pramod/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "\n",
    "\n",
    "class KaggleWord2VecUtility(object):\n",
    "\n",
    "\n",
    "        @staticmethod\n",
    "        def review_to_wordlist(review,stem=False):\n",
    "            # Function to convert a document to a sequence of words,\n",
    "            # optionally removing stop words.  Returns a list of words.\n",
    "            #\n",
    "            tknzr = TweetTokenizer()\n",
    "            new_temp=[]\n",
    "            review=str(review)\n",
    "            new_temp=re.sub('\\\\<.*?\\\\>', \"\", review)\n",
    "            new_temp=re.sub('\\\\http.*[\\s]',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\http.*$',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\@(.*?)[\\s]',\"\",new_temp)\n",
    "            new_temp=re.sub('\\\\@(.*?)$',\"\",new_temp)\n",
    "            #new_temp=re.sub('\\\\#(.*?)[\\s]',\"\",new_temp)# if accuracy is less, try removing this\n",
    "            #new_temp=re.sub('\\\\#(.*?)$',\"\",new_temp)# if accuracy is less, try removing this\n",
    "            new_temp=re.sub(r'[^\\w\\s]',\"\",new_temp)\n",
    "\n",
    "            review_text=re.sub('\\d+', \"\",new_temp)#does this hamper performance\n",
    "\n",
    "            words = review_text.lower().split()\n",
    "            if  stem:\n",
    "                ar1=[]\n",
    "                ps=PorterStemmer()\n",
    "                lanc=LancasterStemmer()\n",
    "                lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "                sno=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "                words = [sno.stem(w) for w in words]\n",
    "                words = [ps.stem(w) for w in words]\n",
    "\n",
    "\n",
    "            return(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import bigrams\n",
    "from nltk.stem.porter import *\n",
    "import xlrd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sklearn\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN,BRkNNaClassifier,BRkNNbClassifier\n",
    "\n",
    "\n",
    "#path = \"D:\\H\\Dataset\\Book_Dataset_clean.csv\"\n",
    "#df = pd.read_csv(path)\n",
    "df = pd.read_csv('/home/pramod/Transfer/Book_Dataset_clean.csv')\n",
    "genre = df['Genre'][0:1000]\n",
    "summ = df[\"Summary\"][0:1000]\n",
    "result = []\n",
    "\n",
    "\n",
    "for xi in genre:\n",
    "    abc = re.sub(r'\"/[a-zA-Z/0-9 ]+\": ',\"\",xi)\n",
    "    abc = re.sub(r'[{}\\\"\\\"]+',\"\",abc)\n",
    "    abc = re.sub(r'\\\\u00e0',\"a\",abc)\n",
    "    abc = re.sub(r'/[a-zA-Z/0-9\\_]+: ',\"\",abc)\n",
    "    abc = re.sub(r', ',\",\",abc)\n",
    "    result.append(abc)\n",
    "    \n",
    "genre_arr = np.array([np.array(xi.split(\",\")) for xi in result])\n",
    "\n",
    "\n",
    "clean_summaries=[]\n",
    "for i in range(0,len(summ)):\n",
    "    clean_summaries.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(summ[i], True)))\n",
    "clean_summaries = np.array(clean_summaries)\n",
    "\n",
    "#print(clean_summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2=[]\n",
    "for i in genre_arr:\n",
    "    arr3=[]\n",
    "    for a in i:\n",
    "        if a == 'Hard science fiction':\n",
    "            b=a.replace('Hard science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Young adult literature':\n",
    "            b=a.replace('Young adult literature',\"Children's literature\")\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical novel':\n",
    "            b=a.replace('Historical novel','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical fiction':\n",
    "            b=a.replace('Historical fiction','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Alternate history':\n",
    "            b=a.replace('Alternate history','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'War novel':\n",
    "            b=a.replace('War novel','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Novella':\n",
    "            b=a.replace('Novella','Novel')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic novel':\n",
    "            b=a.replace('Comic novel','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Autobiographical novel':\n",
    "            b=a.replace('Autobiographical novel','Autobiography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'High fantasy':\n",
    "            b=a.replace('High fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'History':\n",
    "            b=a.replace('History','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Memoir':\n",
    "            b=a.replace('Memoir','Biography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Techno-thriller':\n",
    "            b=a.replace('Techno-thriller','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Steampunk':\n",
    "            b=a.replace('Steampunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Paranormal romance':\n",
    "            b=a.replace('Paranormal romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Romance novel':\n",
    "            b=a.replace('Romance novel','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Picture book':\n",
    "            b=a.replace('Picture book',\"Children's literature\")\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bildungsroman':\n",
    "            b=a.replace('Bildungsroman','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Reference':\n",
    "            b=a.replace('Reference','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Black comedy':\n",
    "            b=a.replace('Black comedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Urban fantasy':\n",
    "            b=a.replace('Urban fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Military science fiction':\n",
    "            b=a.replace('Military science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sword and sorcery':\n",
    "            b=a.replace('Sword and sorcery','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Whodunit':\n",
    "            b=a.replace('Whodunit','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Absurdist fiction':\n",
    "            b=a.replace('Absurdist fiction','Literary fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Hardboiled':\n",
    "            b=a.replace('Hardboiled','Detective fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Science':\n",
    "            b=a.replace('Science','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dark fantasy':\n",
    "            b=a.replace('Dark fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Time travel':\n",
    "            b=a.replace('Time travel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Psychological novel':\n",
    "            b=a.replace('Psychological novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Adventure novel':\n",
    "            b=a.replace('Adventure novel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Wuxia':\n",
    "            b=a.replace('Wuxia','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Picaresque novel':\n",
    "            b=a.replace('Picaresque novel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'True crime':\n",
    "            b=a.replace('True crime','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cyberpunk':\n",
    "            b=a.replace('Cyberpunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical fantasy':\n",
    "            b=a.replace('Historical fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Vampire fiction':\n",
    "            b=a.replace('Vampire fiction','Gothic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Religion':\n",
    "            b=a.replace('Religion','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Scientific romance':\n",
    "            b=a.replace('Scientific romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Lost World':\n",
    "            b=a.replace('Lost World','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Space opera':\n",
    "            b=a.replace('Space opera','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Chivalric romance':\n",
    "            b=a.replace('Chivalric romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'K\\\\u00fcnstlerroman':\n",
    "            b=a.replace('K\\\\u00fcnstlerroman','Kunstlerroman')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Biographical novel':\n",
    "            b=a.replace('Biographical novel','Biography')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Travel literature':\n",
    "            b=a.replace('Travel literature','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Science fantasy':\n",
    "            b=a.replace('Science fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic book':\n",
    "            b=a.replace('Comic book','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Kunstlerroman':\n",
    "            b=a.replace('Kunstlerroman','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Drama':\n",
    "            b=a.replace('Drama','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Parody':\n",
    "            b=a.replace('Parody','Satire')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Travel':\n",
    "            b=a.replace('Travel','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Magic realism':\n",
    "            b=a.replace('Magic realism','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Epistolary novel':\n",
    "            b=a.replace('Epistolary novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #After this\n",
    "        elif a == 'Politics':\n",
    "            b=a.replace('Politics','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Mathematics':\n",
    "            b=a.replace('Mathematics','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Marketing':\n",
    "            b=a.replace('Marketing','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'American Gothic Fiction':\n",
    "            b=a.replace('American Gothic Fiction','Gothic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Police procedural':\n",
    "            b=a.replace('Police procedural','Detective fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Human extinction':\n",
    "            b=a.replace('Human extinction','Apocalyptic and post-apocalyptic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Utopian fiction':\n",
    "            b=a.replace('Utopian fiction','Utopian and dystopian fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Photography':\n",
    "            b=a.replace('Photography','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Future history':\n",
    "            b=a.replace('Future history','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fantastique':\n",
    "            b=a.replace('Fantastique','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Popular culture':\n",
    "            b=a.replace('Popular culture','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Robinsonade':\n",
    "            b=a.replace('Robinsonade','Travel')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Conspiracy':\n",
    "            b=a.replace('Conspiracy','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Colonial United States romance':\n",
    "            b=a.replace('Colonial United States romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Experimental literature':\n",
    "            b=a.replace('Experimental literature','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Religious text':\n",
    "            b=a.replace('Religious text','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'English public-school stories':\n",
    "            b=a.replace('English public-school stories','Fiction')\n",
    "            arr3.append(b)       \n",
    "        elif a == 'School story':\n",
    "            b=a.replace('School story','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == \"Boys' school stories\":\n",
    "            b=a.replace(\"Boys' school stories\",'Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social criticism':\n",
    "            b=a.replace('Social criticism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Computer Science':\n",
    "            b=a.replace('Computer Science','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Pornography':\n",
    "            b=a.replace('Pornography','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bit Lit':\n",
    "            b=a.replace('Bit Lit','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Georgian romance':\n",
    "            b=a.replace('Georgian romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Superhero fiction':\n",
    "            b=a.replace('Superhero fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'New Weird':\n",
    "            b=a.replace('New Weird','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Alien invasion':\n",
    "            b=a.replace('Alien invasion','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Low fantasy':\n",
    "            b=a.replace('Low fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'New York Times Best Seller list':\n",
    "            b=a.replace('New York Times Best Seller list','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Western fiction':\n",
    "            b=a.replace('Western fiction','Western')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Neuroscience':\n",
    "            b=a.replace('Neuroscience','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Juvenile fantasy':\n",
    "            b=a.replace('Juvenile fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Medieval romance':\n",
    "            b=a.replace('Medieval romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Romantic comedy':\n",
    "            b=a.replace('Romantic comedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Foreign legion':\n",
    "            b=a.replace('Foreign legion','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fable':\n",
    "            b=a.replace('Fable','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Elizabethan romance':\n",
    "            b=a.replace('Elizabethan romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Metaphysics':\n",
    "            b=a.replace('Metaphysics','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Bangsian fantasy':\n",
    "            b=a.replace('Bangsian fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Indian chick lit':\n",
    "            b=a.replace('Indian chick lit','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Epic Science Fiction and Fantasy':\n",
    "            b=a.replace('Epic Science Fiction and Fantasy','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Naval adventure':\n",
    "            b=a.replace('Naval adventure','Adventure')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cookbook':\n",
    "            b=a.replace('Cookbook','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Albino bias':\n",
    "            b=a.replace('Albino bias','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Morality play':\n",
    "            b=a.replace('Morality play','Drama')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Polemic':\n",
    "            b=a.replace('Polemic','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Literary criticism':\n",
    "            b=a.replace('Literary criticism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Creative nonfiction':\n",
    "            b=a.replace('Creative nonfiction','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Postcyberpunk':\n",
    "            b=a.replace('Postcyberpunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fairytale fantasy':\n",
    "            b=a.replace('Fairytale fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Modernism':\n",
    "            b=a.replace('Modernism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Political philosophy':\n",
    "            b=a.replace('Political philosophy','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anti-war':\n",
    "            b=a.replace('Anti-war','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Gay Themed':\n",
    "            b=a.replace('Gay Themed','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Military history':\n",
    "            b=a.replace('Military history','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'First-person narrative':\n",
    "            b=a.replace('First-person narrative','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fictional crossover':\n",
    "            b=a.replace('Fictional crossover','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Space western':\n",
    "            b=a.replace('Space western','Western')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social novel':\n",
    "            b=a.replace('Social novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Heroic fantasy':\n",
    "            b=a.replace('Heroic fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sea story':\n",
    "            b=a.replace('Sea story','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Coming of age':\n",
    "            b=a.replace('Coming of age','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Self-help':\n",
    "            b=a.replace('Self-help','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Catastrophic literature':\n",
    "            b=a.replace('Catastrophic literature','Apocalyptic and post-apocalyptic fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dying Earth subgenre':\n",
    "            b=a.replace('Dying Earth subgenre','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Zombies in popular culture':\n",
    "            b=a.replace('Zombies in popular culture','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social sciences':\n",
    "            b=a.replace('Social sciences','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Treatise':\n",
    "            b=a.replace('Treatise','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Essay':\n",
    "            b=a.replace('Essay','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Prose poetry':\n",
    "            b=a.replace('Prose poetry','Prose')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Ergodic literature':\n",
    "            b=a.replace('Ergodic literature','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Non-fiction novel':\n",
    "            b=a.replace('Non-fiction novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'LGBT literature':\n",
    "            b=a.replace('LGBT literature','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Transgender and transsexual fiction':\n",
    "            b=a.replace('Transgender and transsexual fiction','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social commentary':\n",
    "            b=a.replace('Social commentary','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sword and planet':\n",
    "            b=a.replace('Sword and planet','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Biopunk':\n",
    "            b=a.replace('Biopunk','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comedy of manners':\n",
    "            b=a.replace('Comedy of manners','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Locked room mystery':\n",
    "            b=a.replace('Locked room mystery','Mystery')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Industrial novel':\n",
    "            b=a.replace('Industrial novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Industrial novel':\n",
    "            b=a.replace('Industrial novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Mashup':\n",
    "            b=a.replace('Mashup','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Edisonade':\n",
    "            b=a.replace('Edisonade','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Farce':\n",
    "            b=a.replace('Farce','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical romance':\n",
    "            b=a.replace('Historical romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Conspiracy fiction':\n",
    "            b=a.replace('Conspiracy fiction','Thriller')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Spirituality':\n",
    "            b=a.replace('Spirituality','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Zombie':\n",
    "            b=a.replace('Zombie','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Subterranean fiction':\n",
    "            b=a.replace('Subterranean fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Ghost story':\n",
    "            b=a.replace('Ghost story','Horror')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Supernatural':\n",
    "            b=a.replace('Supernatural','Horror')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anthropology':\n",
    "            b=a.replace('Anthropology','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sports':\n",
    "            b=a.replace('Sports','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Post-holocaust':\n",
    "            b=a.replace('Post-holocaust','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic fantasy':\n",
    "            b=a.replace('Comic fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Planetary romance':\n",
    "            b=a.replace('Planetary romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comics':\n",
    "            b=a.replace('Comics','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Chick lit':\n",
    "            b=a.replace('Chick lit','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Cozy':\n",
    "            b=a.replace('Cozy','Crime Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Inspirational':\n",
    "            b=a.replace('Inspirational','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fantasy of manners':\n",
    "            b=a.replace('Fantasy of manners','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Anthology':\n",
    "            b=a.replace('Anthology','Short story')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Contemporary fantasy':\n",
    "            b=a.replace('Contemporary fantasy','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Transhumanism':\n",
    "            b=a.replace('Transhumanism','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Campus novel':\n",
    "            b=a.replace('Campus novel','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Soft science fiction':\n",
    "            b=a.replace('Soft science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic fantasy':\n",
    "            b=a.replace('Comic fantasy','Comic')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Urban fiction':\n",
    "            b=a.replace('Urban fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Social science fiction':\n",
    "            b=a.replace('Social science fiction','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Economics':\n",
    "            b=a.replace('Economics','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Erotica':\n",
    "            b=a.replace('Erotica','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Graphic novel':\n",
    "            b=a.replace('Graphic novel','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Regency romance':\n",
    "            b=a.replace('Regency romance','Romance')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Tragicomedy':\n",
    "            b=a.replace('Tragicomedy','Comedy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Fairy tale':\n",
    "            b=a.replace('Fairy tale','Fantasy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Literary realism':\n",
    "            b=a.replace('Literary realism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Existentialism':\n",
    "            b=a.replace('Existentialism','Philosophy')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Popular science':\n",
    "            b=a.replace('Popular science','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Feminist science fiction':\n",
    "            b=a.replace('Feminist science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Postmodernism':\n",
    "            b=a.replace('Postmodernism','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Personal journal':\n",
    "            b=a.replace('Personal journal','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Gay novel':\n",
    "            b=a.replace('Gay novel','Speculative fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Comic science fiction':\n",
    "            b=a.replace('Comic science fiction','Science Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Historical whodunnit':\n",
    "            b=a.replace('Historical whodunnit','Historical')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Psychology':\n",
    "            b=a.replace('Psychology','Fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Dystopia':\n",
    "            b=a.replace('Dystopia','Utopian and dystopian fiction')\n",
    "            arr3.append(b)\n",
    "        elif a == 'Sociology':\n",
    "            b=a.replace('Sociology','Non-fiction')\n",
    "            arr3.append(b)\n",
    "        else:\n",
    "            arr3.append(a)\n",
    "    arr2.append(arr3)\n",
    "#print (arr2)\n",
    "#print(len(arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Fiction': 622, 'Speculative fiction': 490, 'Science Fiction': 359, 'Novel': 290, 'Fantasy': 197, \"Children's literature\": 192, 'Historical': 100, 'Mystery': 84, 'Non-fiction': 71, 'Suspense': 67, 'Romance': 58, 'Horror': 58, 'Utopian and dystopian fiction': 51, 'Adventure': 43, 'Crime Fiction': 36, 'Thriller': 36, 'Satire': 30, 'Autobiography': 29, 'Comedy': 29, 'Gothic fiction': 20, 'Detective fiction': 20, 'Philosophy': 19, 'Spy fiction': 17, 'Biography': 17, 'Humour': 15, 'Comic': 14, 'Roman a clef': 13, 'Poetry': 11, 'Apocalyptic and post-apocalyptic fiction': 11, 'Literary fiction': 9, 'Short story': 7, 'Western': 5, 'Kunstlerroman': 4, 'Business': 3, 'Music': 2, 'Role-playing game': 2, 'Nature': 2, 'Parallel novel': 2, 'Invasion literature': 1, 'Play': 1, 'Drama': 1, 'Prose': 1})\n",
      "42\n",
      "Counter({'Fiction': 622, 'Speculative fiction': 490, 'Science Fiction': 359, 'Novel': 290, 'Fantasy': 197, \"Children's literature\": 192, 'Historical': 100, 'Mystery': 84, 'Non-fiction': 71, 'Suspense': 67, 'Horror': 58, 'Romance': 58, 'Utopian and dystopian fiction': 51, 'Adventure': 43, 'Crime Fiction': 36, 'Thriller': 36, 'Satire': 30, 'Autobiography': 29, 'Comedy': 29})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for i in genre_arr:\\n    for j in i:\\n        count+=1\\nprint(array2)\\nprint(count)\\n\\nfor i in array2:\\n    for j in i:\\n        count1+=1\\nprint(count1)\\nprint(len(genre_arr))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "array1=[]\n",
    "totals = Counter(i for i in list(itertools.chain.from_iterable(arr2)))\n",
    "\n",
    "print(totals)\n",
    "print(len(totals))\n",
    "\n",
    "for genre in totals:\n",
    "    if totals.get(genre)<=25:\n",
    "        array1.append(genre)\n",
    "array3=[a for a in totals]\n",
    "#print(array3)\n",
    "#print(len(array3))\n",
    "\n",
    "\n",
    "\n",
    "array2=([[genre for genre in i if genre not in array1]for i in arr2])\n",
    "count=0\n",
    "count1=0\n",
    "\n",
    "res = Counter(i for i in list(itertools.chain.from_iterable(array2)))\n",
    "\n",
    "print res\n",
    "'''for i in genre_arr:\n",
    "    for j in i:\n",
    "        count+=1\n",
    "print(array2)\n",
    "print(count)\n",
    "\n",
    "for i in array2:\n",
    "    for j in i:\n",
    "        count1+=1\n",
    "print(count1)\n",
    "print(len(genre_arr))'''\n",
    "#print(len(array2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graph_tool.all",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d88909c33e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelPowerset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIGraphLabelCooccurenceClusterer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelSpacePartitioningClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pramod/anaconda2/lib/python2.7/site-packages/skmultilearn/cluster/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelSpaceClustererBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelCooccurenceClustererBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraphtool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphToolCooccurenceClusterer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0migraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIGraphLabelCooccurenceClusterer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrixLabelSpaceClusterer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pramod/anaconda2/lib/python2.7/site-packages/skmultilearn/cluster/graphtool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named graph_tool.all"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = Pipeline([ \n",
    "    ('vectorizer', TfidfVectorizer(ngram_range(1,4),stop_words='english')),\n",
    "    #('lda', LatentDirichletAllocation()),\n",
    "    ('clf',LabelPowerset(LinearSVC()))])\n",
    "\n",
    "#LabelPowerset(AdaBoostClassifier(base_estimator=LinearSVC(),algorithm='SAMME'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( clean_summaries, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifier=classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "('Adventure', 'Fantasy', 'Fiction', 'Romance', 'Speculative fiction')\n",
      "('Autobiography', 'Fiction', 'Historical')\n",
      "0.492614441114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pramod/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pramod/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print y_pred[1]\n",
    "\n",
    "x=mlb.inverse_transform(y_pred)\n",
    "\n",
    "actual=mlb.inverse_transform(y_test)\n",
    "\n",
    "print actual[1]\n",
    "\n",
    "print x[1]\n",
    "\n",
    "print f1_score(y_test, y_pred, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score\n",
      "0.504722010355\n",
      "Hamming loss\n",
      "0.10304166666666667\n",
      "Cosine similarity\n",
      "[[ 0.57735027  0.          0.57735027 ...,  0.25        0.35355339  0.5       ]\n",
      " [ 0.70710678  0.40824829  0.70710678 ...,  0.40824829  0.57735027\n",
      "   0.61237244]\n",
      " [ 0.33333333  0.57735027  0.33333333 ...,  0.57735027  0.          0.28867513]\n",
      " ..., \n",
      " [ 0.57735027  0.5         0.57735027 ...,  0.25        0.70710678  0.5       ]\n",
      " [ 0.57735027  0.5         0.57735027 ...,  0.5         0.35355339  0.5       ]\n",
      " [ 0.8660254   0.          0.8660254  ...,  0.25        0.70710678  0.75      ]]\n",
      "pairwise_distance\n",
      "[[ 1.73205081  2.23606798  1.73205081 ...,  2.44948974  2.          2.        ]\n",
      " [ 1.73205081  2.23606798  1.73205081 ...,  2.44948974  2.          2.        ]\n",
      " [ 2.          1.41421356  2.         ...,  1.73205081  2.23606798\n",
      "   2.23606798]\n",
      " ..., \n",
      " [ 1.73205081  1.73205081  1.73205081 ...,  2.44948974  1.41421356  2.        ]\n",
      " [ 1.73205081  1.73205081  1.73205081 ...,  2.          2.          2.        ]\n",
      " [ 1.          2.23606798  1.         ...,  2.44948974  1.41421356\n",
      "   1.41421356]]\n",
      "precision_score\n",
      "0.544984126549\n",
      "recall_score\n",
      "0.479544646033\n",
      "accuracy_score\n",
      "135\n",
      "0.135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"F1_score\")\n",
    "print(f1_score(Y, y_pred,average='weighted'))\n",
    "print(\"Hamming loss\")\n",
    "print(hamming_loss(Y, y_pred))\n",
    "#print('Chi2')\n",
    "#print(chi2_kernel(Y, y_pred))\n",
    "print(\"Cosine similarity\")\n",
    "print(cosine_similarity(Y, y_pred))\n",
    "print('pairwise_distance')\n",
    "print(pairwise_distances(Y, y_pred))\n",
    "#print(\"cohen_kappa\")\n",
    "#print(cohen_kappa_score(Y, y_pred))\n",
    "#print(\"log_loss\")\n",
    "#print(log_loss(Y, y_pred))\n",
    "print(\"precision_score\")\n",
    "print(precision_score(Y, y_pred,average='weighted'))\n",
    "print(\"recall_score\")\n",
    "print(recall_score(Y, y_pred,average='weighted'))\n",
    "\n",
    "print(\"accuracy_score\")\n",
    "print (accuracy_score(Y,y_pred,normalize=False))\n",
    "print (accuracy_score(Y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
